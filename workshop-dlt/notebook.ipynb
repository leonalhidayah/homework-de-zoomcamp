{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dlt (data load tool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "it's a tool for extracting, normalizing, and loading data from data source to storage destination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**installing dlt library**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting dlt[duckdb]\n",
      "  Downloading dlt-1.6.1-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: PyYAML>=5.4.1 in c:\\users\\leonhard\\appdata\\roaming\\python\\python310\\site-packages (from dlt[duckdb]) (6.0.1)\n",
      "Requirement already satisfied: click>=7.1 in c:\\users\\leonhard\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from dlt[duckdb]) (8.1.7)\n",
      "Requirement already satisfied: fsspec>=2022.4.0 in c:\\users\\leonhard\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from dlt[duckdb]) (2024.6.1)\n",
      "Requirement already satisfied: gitpython>=3.1.29 in c:\\users\\leonhard\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from dlt[duckdb]) (3.1.40)\n",
      "Collecting giturlparse>=0.10.0 (from dlt[duckdb])\n",
      "  Downloading giturlparse-0.12.0-py2.py3-none-any.whl.metadata (4.5 kB)\n",
      "Collecting hexbytes>=0.2.2 (from dlt[duckdb])\n",
      "  Downloading hexbytes-1.3.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting humanize>=4.4.0 (from dlt[duckdb])\n",
      "  Downloading humanize-4.12.0-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting jsonpath-ng>=1.5.3 (from dlt[duckdb])\n",
      "  Downloading jsonpath_ng-1.7.0-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: makefun>=1.15.0 in c:\\users\\leonhard\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from dlt[duckdb]) (1.15.2)\n",
      "Collecting orjson!=3.10.1,!=3.9.11,!=3.9.12,!=3.9.13,!=3.9.14,<4,>=3.6.7 (from dlt[duckdb])\n",
      "  Downloading orjson-3.10.15-cp310-cp310-win_amd64.whl.metadata (42 kB)\n",
      "Requirement already satisfied: packaging>=21.1 in c:\\users\\leonhard\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from dlt[duckdb]) (23.2)\n",
      "Collecting pathvalidate>=2.5.2 (from dlt[duckdb])\n",
      "  Downloading pathvalidate-3.2.3-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting pendulum>=2.1.2 (from dlt[duckdb])\n",
      "  Downloading pendulum-3.0.0-cp310-none-win_amd64.whl.metadata (7.0 kB)\n",
      "Collecting pluggy>=1.3.0 (from dlt[duckdb])\n",
      "  Downloading pluggy-1.5.0-py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting pytz>=2022.6 (from dlt[duckdb])\n",
      "  Downloading pytz-2025.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Requirement already satisfied: pywin32>=306 in c:\\users\\leonhard\\appdata\\roaming\\python\\python310\\site-packages (from dlt[duckdb]) (306)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\leonhard\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from dlt[duckdb]) (2.31.0)\n",
      "Collecting requirements-parser>=0.5.0 (from dlt[duckdb])\n",
      "  Downloading requirements_parser-0.11.0-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting rich-argparse<2.0.0,>=1.6.0 (from dlt[duckdb])\n",
      "  Downloading rich_argparse-1.7.0-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting semver>=3.0.0 (from dlt[duckdb])\n",
      "  Downloading semver-3.0.4-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: setuptools>=65.6.0 in c:\\users\\leonhard\\appdata\\roaming\\python\\python310\\site-packages (from dlt[duckdb]) (75.6.0)\n",
      "Collecting simplejson>=3.17.5 (from dlt[duckdb])\n",
      "  Downloading simplejson-3.20.1-cp310-cp310-win_amd64.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: tenacity>=8.0.2 in c:\\users\\leonhard\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from dlt[duckdb]) (8.2.3)\n",
      "Collecting tomlkit>=0.11.3 (from dlt[duckdb])\n",
      "  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\leonhard\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from dlt[duckdb]) (4.9.0)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\leonhard\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from dlt[duckdb]) (2023.3)\n",
      "Collecting win-precise-time>=1.4.2 (from dlt[duckdb])\n",
      "  Downloading win_precise_time-1.4.2-cp310-cp310-win_amd64.whl.metadata (3.0 kB)\n",
      "Collecting duckdb>=0.9 (from dlt[duckdb])\n",
      "  Downloading duckdb-1.2.0-cp310-cp310-win_amd64.whl.metadata (995 bytes)\n",
      "Requirement already satisfied: colorama in c:\\users\\leonhard\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from click>=7.1->dlt[duckdb]) (0.4.6)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\leonhard\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gitpython>=3.1.29->dlt[duckdb]) (4.0.11)\n",
      "Requirement already satisfied: ply in c:\\users\\leonhard\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jsonpath-ng>=1.5.3->dlt[duckdb]) (3.11)\n",
      "Requirement already satisfied: python-dateutil>=2.6 in c:\\users\\leonhard\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pendulum>=2.1.2->dlt[duckdb]) (2.8.2)\n",
      "Collecting time-machine>=2.6.0 (from pendulum>=2.1.2->dlt[duckdb])\n",
      "  Downloading time_machine-2.16.0-cp310-cp310-win_amd64.whl.metadata (21 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\leonhard\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.26.0->dlt[duckdb]) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\leonhard\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.26.0->dlt[duckdb]) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\leonhard\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.26.0->dlt[duckdb]) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\leonhard\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.26.0->dlt[duckdb]) (2023.11.17)\n",
      "Collecting types-setuptools>=69.1.0 (from requirements-parser>=0.5.0->dlt[duckdb])\n",
      "  Downloading types_setuptools-75.8.0.20250210-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: rich>=11.0.0 in c:\\users\\leonhard\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from rich-argparse<2.0.0,>=1.6.0->dlt[duckdb]) (13.7.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\leonhard\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython>=3.1.29->dlt[duckdb]) (5.0.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\leonhard\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-dateutil>=2.6->pendulum>=2.1.2->dlt[duckdb]) (1.16.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\leonhard\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from rich>=11.0.0->rich-argparse<2.0.0,>=1.6.0->dlt[duckdb]) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\leonhard\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from rich>=11.0.0->rich-argparse<2.0.0,>=1.6.0->dlt[duckdb]) (2.17.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\leonhard\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=11.0.0->rich-argparse<2.0.0,>=1.6.0->dlt[duckdb]) (0.1.2)\n",
      "Downloading duckdb-1.2.0-cp310-cp310-win_amd64.whl (11.4 MB)\n",
      "   ---------------------------------------- 0.0/11.4 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.5/11.4 MB 3.4 MB/s eta 0:00:04\n",
      "   --- ------------------------------------ 1.0/11.4 MB 3.3 MB/s eta 0:00:04\n",
      "   ------ --------------------------------- 1.8/11.4 MB 3.2 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 2.6/11.4 MB 3.4 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 3.7/11.4 MB 3.6 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 4.5/11.4 MB 3.8 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 5.8/11.4 MB 4.1 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 6.8/11.4 MB 4.2 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 7.9/11.4 MB 4.3 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 8.9/11.4 MB 4.4 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 10.0/11.4 MB 4.5 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 11.0/11.4 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.4/11.4 MB 4.5 MB/s eta 0:00:00\n",
      "Downloading giturlparse-0.12.0-py2.py3-none-any.whl (15 kB)\n",
      "Downloading hexbytes-1.3.0-py3-none-any.whl (4.9 kB)\n",
      "Downloading humanize-4.12.0-py3-none-any.whl (127 kB)\n",
      "Downloading jsonpath_ng-1.7.0-py3-none-any.whl (30 kB)\n",
      "Downloading orjson-3.10.15-cp310-cp310-win_amd64.whl (133 kB)\n",
      "Downloading pathvalidate-3.2.3-py3-none-any.whl (24 kB)\n",
      "Downloading pendulum-3.0.0-cp310-none-win_amd64.whl (293 kB)\n",
      "Downloading pluggy-1.5.0-py3-none-any.whl (20 kB)\n",
      "Downloading pytz-2025.1-py2.py3-none-any.whl (507 kB)\n",
      "Downloading requirements_parser-0.11.0-py3-none-any.whl (14 kB)\n",
      "Downloading rich_argparse-1.7.0-py3-none-any.whl (25 kB)\n",
      "Downloading semver-3.0.4-py3-none-any.whl (17 kB)\n",
      "Downloading simplejson-3.20.1-cp310-cp310-win_amd64.whl (75 kB)\n",
      "Downloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
      "Downloading win_precise_time-1.4.2-cp310-cp310-win_amd64.whl (14 kB)\n",
      "Downloading dlt-1.6.1-py3-none-any.whl (884 kB)\n",
      "   ---------------------------------------- 0.0/884.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 884.3/884.3 kB 4.4 MB/s eta 0:00:00\n",
      "Downloading time_machine-2.16.0-cp310-cp310-win_amd64.whl (19 kB)\n",
      "Downloading types_setuptools-75.8.0.20250210-py3-none-any.whl (71 kB)\n",
      "Installing collected packages: pytz, win-precise-time, types-setuptools, tomlkit, simplejson, semver, pluggy, pathvalidate, orjson, jsonpath-ng, humanize, hexbytes, giturlparse, duckdb, time-machine, requirements-parser, rich-argparse, pendulum, dlt\n",
      "  Attempting uninstall: pytz\n",
      "    Found existing installation: pytz 2022.2.1\n",
      "    Uninstalling pytz-2022.2.1:\n",
      "      Successfully uninstalled pytz-2022.2.1\n",
      "Successfully installed dlt-1.6.1 duckdb-1.2.0 giturlparse-0.12.0 hexbytes-1.3.0 humanize-4.12.0 jsonpath-ng-1.7.0 orjson-3.10.15 pathvalidate-3.2.3 pendulum-3.0.0 pluggy-1.5.0 pytz-2025.1 requirements-parser-0.11.0 rich-argparse-1.7.0 semver-3.0.4 simplejson-3.20.1 time-machine-2.16.0 tomlkit-0.13.2 types-setuptools-75.8.0.20250210 win-precise-time-1.4.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install dlt[duckdb]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1: Checking dlt library version**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[39mdlt 1.6.1\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!dlt --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dlt version: 1.6.1\n"
     ]
    }
   ],
   "source": [
    "import dlt\n",
    "\n",
    "print(\"dlt version:\", dlt.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2: Define & Run the Pipeline (NYC Taxi API)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dlt\n",
    "from dlt.sources.helpers.rest_client import RESTClient\n",
    "from dlt.sources.helpers.rest_client.paginators import PageNumberPaginator\n",
    "\n",
    "\n",
    "# your code is here\n",
    "# Define the API resource for NYC taxi data\n",
    "@dlt.resource(\n",
    "    name=\"rides\"\n",
    ")  # <--- The name of the resource (will be used as the table name)\n",
    "def ny_taxi():\n",
    "    client = RESTClient(\n",
    "        base_url=\"https://us-central1-dlthub-analytics.cloudfunctions.net\",\n",
    "        paginator=PageNumberPaginator(base_page=1, total_path=None),\n",
    "    )\n",
    "\n",
    "    for page in client.paginate(\n",
    "        \"data_engineering_zoomcamp_api\"\n",
    "    ):  # <--- API endpoint for retrieving taxi ride data\n",
    "        yield page  # <--- yield data to manage memory\n",
    "\n",
    "\n",
    "# Create a pipeline\n",
    "pipeline = dlt.pipeline(\n",
    "    pipeline_name=\"ny_taxi_pipeline\", destination=\"duckdb\", dataset_name=\"ny_taxi_data\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline ny_taxi_pipeline load step completed in 3.33 seconds\n",
      "1 load package(s) were loaded to destination duckdb and into dataset ny_taxi_data\n",
      "The duckdb destination used duckdb:///b:\\Belajar\\data engineering\\homework-de-zoomcamp\\workshop-dlt\\ny_taxi_pipeline.duckdb location to store data\n",
      "Load package 1739630968.4035795 is LOADED and contains no failed jobs\n"
     ]
    }
   ],
   "source": [
    "load_info = pipeline.run(ny_taxi)\n",
    "print(load_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>database</th>\n",
       "      <th>schema</th>\n",
       "      <th>name</th>\n",
       "      <th>column_names</th>\n",
       "      <th>column_types</th>\n",
       "      <th>temporary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ny_taxi_pipeline</td>\n",
       "      <td>ny_taxi_data</td>\n",
       "      <td>_dlt_loads</td>\n",
       "      <td>[load_id, schema_name, status, inserted_at, sc...</td>\n",
       "      <td>[VARCHAR, VARCHAR, BIGINT, TIMESTAMP WITH TIME...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ny_taxi_pipeline</td>\n",
       "      <td>ny_taxi_data</td>\n",
       "      <td>_dlt_pipeline_state</td>\n",
       "      <td>[version, engine_version, pipeline_name, state...</td>\n",
       "      <td>[BIGINT, BIGINT, VARCHAR, VARCHAR, TIMESTAMP W...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ny_taxi_pipeline</td>\n",
       "      <td>ny_taxi_data</td>\n",
       "      <td>_dlt_version</td>\n",
       "      <td>[version, engine_version, inserted_at, schema_...</td>\n",
       "      <td>[BIGINT, BIGINT, TIMESTAMP WITH TIME ZONE, VAR...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ny_taxi_pipeline</td>\n",
       "      <td>ny_taxi_data</td>\n",
       "      <td>rides</td>\n",
       "      <td>[end_lat, end_lon, fare_amt, passenger_count, ...</td>\n",
       "      <td>[DOUBLE, DOUBLE, DOUBLE, BIGINT, VARCHAR, DOUB...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           database        schema                 name  \\\n",
       "0  ny_taxi_pipeline  ny_taxi_data           _dlt_loads   \n",
       "1  ny_taxi_pipeline  ny_taxi_data  _dlt_pipeline_state   \n",
       "2  ny_taxi_pipeline  ny_taxi_data         _dlt_version   \n",
       "3  ny_taxi_pipeline  ny_taxi_data                rides   \n",
       "\n",
       "                                        column_names  \\\n",
       "0  [load_id, schema_name, status, inserted_at, sc...   \n",
       "1  [version, engine_version, pipeline_name, state...   \n",
       "2  [version, engine_version, inserted_at, schema_...   \n",
       "3  [end_lat, end_lon, fare_amt, passenger_count, ...   \n",
       "\n",
       "                                        column_types  temporary  \n",
       "0  [VARCHAR, VARCHAR, BIGINT, TIMESTAMP WITH TIME...      False  \n",
       "1  [BIGINT, BIGINT, VARCHAR, VARCHAR, TIMESTAMP W...      False  \n",
       "2  [BIGINT, BIGINT, TIMESTAMP WITH TIME ZONE, VAR...      False  \n",
       "3  [DOUBLE, DOUBLE, DOUBLE, BIGINT, VARCHAR, DOUB...      False  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import duckdb\n",
    "\n",
    "# A database '<pipeline_name>.duckdb' was created in working directory so just connect to it\n",
    "\n",
    "# Connect to the DuckDB database\n",
    "conn = duckdb.connect(f\"{pipeline.pipeline_name}.duckdb\")\n",
    "\n",
    "# Set search path to the dataset\n",
    "conn.sql(f\"SET search_path = '{pipeline.dataset_name}'\")\n",
    "\n",
    "# Describe the dataset\n",
    "conn.sql(\"DESCRIBE\").df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3: Explore the loaded data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 18 columns):\n",
      " #   Column                  Non-Null Count  Dtype              \n",
      "---  ------                  --------------  -----              \n",
      " 0   end_lat                 10000 non-null  float64            \n",
      " 1   end_lon                 10000 non-null  float64            \n",
      " 2   fare_amt                10000 non-null  float64            \n",
      " 3   passenger_count         10000 non-null  int64              \n",
      " 4   payment_type            10000 non-null  object             \n",
      " 5   start_lat               10000 non-null  float64            \n",
      " 6   start_lon               10000 non-null  float64            \n",
      " 7   tip_amt                 10000 non-null  float64            \n",
      " 8   tolls_amt               10000 non-null  float64            \n",
      " 9   total_amt               10000 non-null  float64            \n",
      " 10  trip_distance           10000 non-null  float64            \n",
      " 11  trip_dropoff_date_time  10000 non-null  datetime64[us, UTC]\n",
      " 12  trip_pickup_date_time   10000 non-null  datetime64[us, UTC]\n",
      " 13  surcharge               10000 non-null  float64            \n",
      " 14  vendor_name             10000 non-null  object             \n",
      " 15  _dlt_load_id            10000 non-null  object             \n",
      " 16  _dlt_id                 10000 non-null  object             \n",
      " 17  store_and_forward       135 non-null    float64            \n",
      "dtypes: datetime64[us, UTC](2), float64(11), int64(1), object(4)\n",
      "memory usage: 1.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df = pipeline.dataset(dataset_type=\"default\").rides.df()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4: Trip Duration Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(12.3049,)]\n"
     ]
    }
   ],
   "source": [
    "with pipeline.sql_client() as client:\n",
    "    res = client.execute_sql(\n",
    "        \"\"\"\n",
    "            SELECT\n",
    "            AVG(date_diff('minute', trip_pickup_date_time, trip_dropoff_date_time))\n",
    "            FROM rides;\n",
    "            \"\"\"\n",
    "    )\n",
    "    # Prints column values of the first row\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average trip duration: 12.304918333333335 minutes\n"
     ]
    }
   ],
   "source": [
    "# Calculate the trip duration in minutes\n",
    "df[\"trip_duration\"] = (\n",
    "    df[\"trip_dropoff_date_time\"] - df[\"trip_pickup_date_time\"]\n",
    ").dt.total_seconds() / 60\n",
    "\n",
    "# Calculate the average trip duration\n",
    "average_trip_duration = df[\"trip_duration\"].mean()\n",
    "print(f\"Average trip duration: {average_trip_duration} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
